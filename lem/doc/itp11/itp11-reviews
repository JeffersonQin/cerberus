----------------------- REVIEW 1 ---------------------
PAPER: 21
TITLE: Lightweight Tools for Heavyweight Semantics
AUTHORS: Scott Owens, Peter Boehm, Francesco Zappa Nardelli and Peter Sewell

OVERALL RATING: 2 (accept)
REVIEWER'S CONFIDENCE: 2 (medium)

Summary:
The paper presents work-in-progress of a tool called Lem. Lem's focus is to aid large-scale formal developments of "key computational infrastructure". The user can specify syntax and semantics of the language of interest, which are translated by Lem into code of the supported theorem prover of choice. Proofs, however, are to be carried out by the user in the chosen theorem prover. The language supported by Lem is general enough to be straightforwardly translated into the supported theorem provers. The benefit of using Lem in large-scale formal developments is that it moves away from the focus on one specific theorem prover. As such it forms a contribution to one of the application areas of interactive theorem proving.

Strengths:
- there seems to be a niche for tools such as Lem

- this work has clear practical applications

Weaknesses:
- from a scientific perspective not a major contribution

Details:
Because Lem's support for several theorem provers, it is unavoidable to make use of a general language. The authors claim that a straightforward translation into the logic of each of the supported theorem provers is possible, so I expect that the variation in each of the theorem prover specific translations is not huge. Essentially the tool forces the user to develop its definitions in a "weak enough" language, thereby forgoing both exploitable strengths and required extensive expertise of a specific theorem prover. Therefore, I believe that the point of partitioned theorem prover schools the authors make in the section "Motivation" is not a strong one.

One aspect that drew my attention is the support for type classes. This sounds like a very welcome feature and an obvious strength of Lem to me. Unfortunately, it is only mentioned a few times, scattered throughout the paper.

It remains unclear to me how results (lemmas) obtained in various theorem provers within the same project are to be combined in practice, even after reading the very last paragraph. Do the authors envision the results to be completely independent? Or do they intend to somehow import them (as axioms)? Some discussion on this subject would be welcome.

A few more points:
- I don't really get the message of the paragraph before point 1 on page 3. The use of "rather" in its first sentence seems unnecessary.

- The explanation of point 4 on page 5 is weak. I would like to see a concrete example of a good error message.


----------------------- REVIEW 2 ---------------------
PAPER: 21
TITLE: Lightweight Tools for Heavyweight Semantics
AUTHORS: Scott Owens, Peter Boehm, Francesco Zappa Nardelli and Peter Sewell

OVERALL RATING: 2 (accept)
REVIEWER'S CONFIDENCE: 3 (high)

This Rough Diamond outlines an implemented language, LEM, for defining
the semantics of computer systems.  The paper, which is very nicely
written, clearly lays out four goals, as well as explaining the key
motivation of providing a single language for which computer system
semantics can be expressed and then translated into one's favorite
theorem proving environment.  The Diamond "sparkles" in that there is
an implementation and two projects that use it.  It is still Rough as
explained in the conclusion of the paper:

 Although Lem is primarily a design and engineering project, it would
 benefit from a rigorous understanding of exactly how the semantics
 of the source and target logics relate to each other, for the
 fragments we consider. In particular, when multiple provers are used
 to verify properties of a Lem-specified system, we would like a
 semantic justification that the resulting definitions have the same
 meaning, and that a lemma verified in one prover can be used in
 another.

I believe that the above issue is ultimately quite important for
correctness, though one could presumably limp along by convincing
oneself in each case that the translation into the language of one's
prover is suitable.

I'm not aware of any related such work that has been published, other
than the authors' own work on Ott, which they explain is
complementary.

Thus, this paper makes a fine Rough Diamond.  I recommend acceptance.

My only remaining comment is on the following sentence:

 Ultimately, we would like to directly generate OCaml that searches
 for derivations; this will be particularly useful in conjunction
 with Ott, for running test and example programs directly on an
 operational semantics.

I didn't understand what was meant by "derivations"; I guess this
has something to do with deriving executable code from relational
specifications, but I'm not sure, and I think that a bit of
clarification would be useful.


----------------------- REVIEW 3 ---------------------
PAPER: 21
TITLE: Lightweight Tools for Heavyweight Semantics
AUTHORS: Scott Owens, Peter Boehm, Francesco Zappa Nardelli and Peter Sewell

OVERALL RATING: 1 (weak accept)
REVIEWER'S CONFIDENCE: 2 (medium)

The authors have designed an intermediate language LEM to help port definitions(models) between existing proof assistants. LEM can also be used as a intermediate language when generating definitions from domain-specific tools. The design and implementation of LEM was done taking into consideration the following four features: Readability of LEM sources, automated production-quality typesetting preserving source-file formatting and layout, support for execution, and finally quick parsing/type-checking with good error messages.  In future work, the authors plan more backends and express interest in frontends for Coq and Isabelle/HOL. And finally they point out that LEM would benefit from a rigorous understanding of how the semantics of source and target logics relate.

The described work is well motivated and practically useful, for example if someone was a Coq expert and wanted to verify in Coq an application running on ARM down to the bit level, he would save significant modeling effort by reusing the ARM semantics written by a HOL4 expert. This could be possible with LEM tool support.  Of course the translation might not be as robust as one would like it to be, but perhaps the effort to manually mend the translated Coq code is much less than the effort to write the Coq model from scratch.  But in the long run, in the bigger picture, this is not an elegant solution, one would ideally want code reuse which is more than superficial source-level porting, the reuse of code and lemmas should provide semantic guarantees. This is a hard problem, and this paper does not address what one would like ideally. So it seems like a good engineering idea, but to make it semantically rigorous would require a lot of work.


----------------------- REVIEW 4 ---------------------
PAPER: 21
TITLE: Lightweight Tools for Heavyweight Semantics
AUTHORS: Scott Owens, Peter Boehm, Francesco Zappa Nardelli and Peter Sewell

OVERALL RATING: 2 (accept)
REVIEWER'S CONFIDENCE: 3 (high)

This rough diamond paper describes LEM, a specification language that
is designed to make it easier to port definitions between theorem
provers and programming languages. The set of language features that
can be expressed in LEM is approximately the intersection of features
available in the target logics and languages, and there is a
translation pass that attempts to recast missing language features of
the target in terms of known language features, and also binds to
native standard libraries of finite maps, etc. Additionally, instead
of designing a pretty-printer for the target languages, the compiler
attempts to preserve the LEM source text as closely as possible,
including comments, for maximal readability of the resulting
specification.

This is a well-written paper describing a useful and novel technique
for porting specifications between systems, including strong
motivation for its existence and design, and clear delineation of its
scope and related systems. I have no hesitation in recommending its
acceptance for ITP.

